import os
from openai import OpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from PyPDF2 import PdfReader
import chromadb
from dotenv import load_dotenv

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∫–ª—é—á
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 1. –ó—á–∏—Ç—É–≤–∞–Ω–Ω—è PDF
def load_pdf(file_path):
    reader = PdfReader(file_path)
    text = ""
    for page in reader.pages:
        text += page.extract_text()
    return text

# 2. –†–æ–∑–±–∏—Ç—Ç—è –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
def split_text(text):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=100
    )
    return splitter.split_text(text)

# 3. –û—Ç—Ä–∏–º–∞–Ω–Ω—è embedding
def get_embedding(text):
    result = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return result.data[0].embedding

# 4. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è ChromaDB —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
def build_vector_db(chunks):
    chroma_client = chromadb.Client()
    collection = chroma_client.create_collection(name="book")

    for i, chunk in enumerate(chunks):
        emb = get_embedding(chunk)
        collection.add(documents=[chunk], embeddings=[emb], ids=[str(i)])

    return collection

# 5. –ü–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö —á–∞—Å—Ç–∏–Ω
def retrieve_context(question, collection, top_k=3):
    query_emb = get_embedding(question)
    results = collection.query(query_embeddings=[query_emb], n_results=top_k)
    return "\n".join(results["documents"][0])

# 6. –í—ñ–¥–ø–æ–≤—ñ–¥—å GPT
def ask_gpt(context, question):
    messages = [
        {"role": "system", "content": "–¢–∏ –∞—Å–∏—Å—Ç–µ–Ω—Ç, —è–∫–∏–π –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –Ω–∞ –æ—Å–Ω–æ–≤—ñ –Ω–∞–¥–∞–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É."},
        {"role": "user", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–ü–∏—Ç–∞–Ω–Ω—è: {question}"}
    ]
    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        temperature=0.3
    )
    return response.choices[0].message.content

# === –û–°–ù–û–í–ù–ò–ô –°–¶–ï–ù–ê–†–Ü–ô ===
if __name__ == "__main__":
    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂ PDF
    text = load_pdf("book.pdf")
    print("‚úÖ PDF –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ")

    # 2. –†–æ–∑–±–∏–π –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
    chunks = split_text(text)
    print(f"‚úÖ –†–æ–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —á–∞—Å—Ç–∏–Ω")

    # 3. –ü–æ–±—É–¥—É–π –±–∞–∑—É –∑–Ω–∞–Ω—å
    collection = build_vector_db(chunks)
    print("‚úÖ –í–µ–∫—Ç–æ—Ä–Ω—É –ë–î –ø–æ–±—É–¥–æ–≤–∞–Ω–æ")

    # 4. –î—ñ–∞–ª–æ–≥
    while True:
        query = input("\nüßë –í–∏: ")
        if query.lower() in ['–≤–∏—Ö—ñ–¥', 'exit', 'quit']:
            break

        context = retrieve_context(query, collection)
        answer = ask_gpt(context, query)
        print(f"\nü§ñ –ë–æ—Ç: {answer}")
